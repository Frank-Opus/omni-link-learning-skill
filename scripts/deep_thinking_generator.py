#!/usr/bin/env python3
"""
æ·±åº¦æ€è€ƒç”Ÿæˆå™¨ v8.0
æ ¹æ® deep_thinking_template.md æ¨¡æ¿ç”Ÿæˆæ·±åº¦æ€è€ƒæŠ¥å‘Š
"""

import argparse
import re
from pathlib import Path


def split_sentences(text: str) -> list:
    """æ™ºèƒ½åˆ†å‰² ASR è½¬å½•æ–‡æœ¬ï¼ˆæ— æ ‡ç‚¹æˆ–ç©ºæ ¼åˆ†éš”ï¼‰"""
    # å…ˆæŒ‰å¸¸è§è¿æ¥è¯åˆ†å‰²
    connectors = ['ç„¶å', 'æ‰€ä»¥', 'ä½†æ˜¯', 'å› ä¸º', 'å¦‚æœ', 'è™½ç„¶', 'è€Œä¸”', 'å¦å¤–', 'å…¶å®', 'å¯¹å§', 'å°±æ˜¯', 'æˆ‘è§‰å¾—', 'æˆ‘è®¤ä¸º']
    
    sentences = []
    current = ""
    
    # æŒ‰å¥å·å’Œç©ºæ ¼åˆ†å‰²
    parts = re.split(r'[.!?ã€‚ï¼ï¼Ÿ\s]{2,}', text)
    
    for part in parts:
        part = part.strip()
        if len(part) > 10:
            # æ£€æŸ¥æ˜¯å¦åŒ…å«è¿æ¥è¯ï¼Œå¦‚æœæ˜¯åˆ™è¿›ä¸€æ­¥åˆ†å‰²
            for conn in connectors:
                if conn in part and len(part) > 80:
                    sub_parts = part.split(conn)
                    for i, sub in enumerate(sub_parts):
                        if i > 0 and len(sub.strip()) > 10:
                            sentences.append(conn + sub.strip())
                        elif len(sub.strip()) > 10:
                            sentences.append(sub.strip())
                    break
            else:
                sentences.append(part)
    
    # è¿‡æ»¤å¤ªçŸ­æˆ–å¤ªé•¿çš„
    sentences = [s for s in sentences if 20 < len(s) < 500]
    
    return sentences


def extract_key_themes(text: str) -> list:
    """ä»æ–‡æœ¬ä¸­æå–å…³é”®ä¸»é¢˜"""
    themes = []
    
    # é¢„å®šä¹‰çš„ä¸»é¢˜å…³é”®è¯
    theme_keywords = {
        "å·¨å¤´ç«äº‰": ["å·¨å¤´", "å¤§å…¬å¸", "ç«äº‰", "å£å’", "æŠ¤åŸæ²³"],
        "AI ç¡¬ä»¶": ["ç¡¬ä»¶", "æ‰‹æœº", "è®¾å¤‡", "è±†åŒ…æ‰‹æœº"],
        "è±†åŒ…é¢„æµ‹": ["è±†åŒ…", "DAU", "é¢„æµ‹", "27 å¹´"],
        "å¾®ä¿¡ AI": ["å¾®ä¿¡", "AI", "å¤šæ¨¡æ€"],
        "æ–°å…¬å¸å½¢æ€": ["ç»„ç»‡", "å›¢é˜Ÿ", "å…¬å¸", "1-2 ä¸ª", "è¶…äºº"],
        "çº¿æ€§å¤–æ¨": ["çº¿æ€§", "æŒ‡æ•°", "å¤–æ¨", "å¢é•¿"],
        "æ³¡æ²«è®º": ["æ³¡æ²«", "ä¼°å€¼", "å‘¨æœŸ"],
        "ACGN é‡åš": ["ACGN", "åŠ¨ç”»", "æ¼«ç”»", "æ¸¸æˆ", "çŸ­å‰§", "é‡åš"],
        "ç”Ÿæˆæ•°å­—åŒ–": ["æ•°æ®", "æ•°å­—åŒ–", "äº§ç”Ÿ", "è®°å½•"],
        "AI è¯­éŸ³åˆ†æ": ["å½•éŸ³", "è¯­éŸ³", "åˆ†æ", "ç†è§£"]
    }
    
    sentences = split_sentences(text)
    
    for theme, keywords in theme_keywords.items():
        for sent in sentences:
            if any(kw in sent for kw in keywords):
                themes.append((theme, sent))
                break
    
    return themes[:8]  # è¿”å›æœ€å¤š 8 ä¸ªä¸»é¢˜


def generate_deep_thinking(text: str) -> str:
    """ç”Ÿæˆæ·±åº¦æ€è€ƒæŠ¥å‘Š"""
    
    themes = extract_key_themes(text)
    
    report = "# ğŸ§  æ·±åº¦æ€è€ƒæŠ¥å‘Š\n\n"
    report += "**è¯´æ˜**: æœ¬é›†å¯¹è¯çš„æ·±åº¦è§£è¯»ä¸æ€è€ƒï¼ŒåŸæ–‡å¼•ç”¨æå°‘ï¼Œä¸»è¦æ˜¯æ¶ˆåŒ–åçš„åˆ†æã€‚\n\n"
    report += "---\n\n"
    
    # ========== ç¬¬ä¸€éƒ¨åˆ†ï¼šæ ¸å¿ƒæ´å¯Ÿ ==========
    report += "## ä¸€ã€æ ¸å¿ƒæ´å¯Ÿ\n\n"
    
    for i, (theme, quote) in enumerate(themes[:5], 1):
        report += f"### {i}. å…³äºã€Œ{theme}ã€çš„æ·±å±‚æ€è€ƒ\n\n"
        report += f"**speaker è§‚ç‚¹**: {quote[:100]}...\n\n"
        
        report += "**æˆ‘çš„æ·±åº¦åˆ†æ**:\n\n"
        report += f"[è¿™é‡Œéœ€è¦æ·±å…¥åˆ†æ {theme} è¿™ä¸ªä¸»é¢˜]\n\n"
        
        report += "è¿™ä¸ªè§‚ç‚¹èƒŒåæœ‰å‡ ä¸ªéšå«å‰æï¼š\n"
        report += "1. [å‰æ 1 - éœ€è¦åˆ†æ]\n"
        report += "2. [å‰æ 2 - éœ€è¦åˆ†æ]\n"
        report += "3. [å‰æ 3 - éœ€è¦åˆ†æ]\n\n"
        
        report += "**æˆ‘æƒ³åˆ°çš„æ¡ˆä¾‹/é—®é¢˜/æœºä¼š**:\n"
        report += f"- [æ¡ˆä¾‹ 1 - ä¸ {theme} ç›¸å…³]\n"
        report += f"- [æ¡ˆä¾‹ 2 - ä¸ {theme} ç›¸å…³]\n"
        report += f"- [æ¡ˆä¾‹ 3 - ä¸ {theme} ç›¸å…³]\n\n"
        
        report += "**æˆ‘çš„åˆ¤æ–­**:\n"
        report += f"[å¯¹ {theme} çš„ç‹¬ç«‹åˆ¤æ–­]\n\n"
        
        report += "**è¡ŒåŠ¨å»ºè®®**:\n"
        report += f"- [å…·ä½“å»ºè®® 1]\n"
        report += f"- [å…·ä½“å»ºè®® 2]\n"
        report += f"- [å…·ä½“å»ºè®® 3]\n\n"
        
        report += "---\n\n"
    
    # ========== ç¬¬äºŒéƒ¨åˆ†ï¼šæœ€å—å¯å‘çš„ç‚¹ ==========
    report += "## äºŒã€æœ¬é›†æˆ‘æœ€å—å¯å‘çš„ 5 ä¸ªç‚¹\n\n"
    
    for i in range(1, 6):
        report += f"{i}. **[æ´å¯Ÿ{i}]** â€”â€” [ä¸ºä»€ä¹ˆå—å¯å‘]\n\n"
    
    report += "---\n\n"
    
    # ========== ç¬¬ä¸‰éƒ¨åˆ†ï¼šæˆ‘çš„ç–‘é—® ==========
    report += "## ä¸‰ã€æˆ‘çš„ 5 ä¸ªç–‘é—®\n\n"
    
    for i in range(1, 6):
        report += f"{i}. **[ç–‘é—®{i}]** â€”â€” [ä¸ºä»€ä¹ˆæœ‰ç–‘é—®]\n\n"
    
    report += "---\n\n"
    
    # ========== ç¬¬å››éƒ¨åˆ†ï¼šè¦åšçš„äº‹ ==========
    report += "## å››ã€æˆ‘æ¥ä¸‹æ¥è¦åšçš„ 5 ä»¶äº‹\n\n"
    
    for i in range(1, 6):
        report += f"{i}. **[äº‹é¡¹{i}]** â€”â€” [å…·ä½“æ€ä¹ˆåš]\n\n"
    
    report += "---\n\n"
    
    # ========== ç¬¬äº”éƒ¨åˆ†ï¼šæ‰¹åˆ¤æ€§æ€è€ƒ ==========
    report += "## äº”ã€æ‰¹åˆ¤æ€§æ€è€ƒ\n\n"
    
    report += "**æˆ‘åŒæ„çš„è§‚ç‚¹**:\n"
    report += "1. [è§‚ç‚¹] â€”â€” [ä¸ºä»€ä¹ˆåŒæ„]\n"
    report += "2. [è§‚ç‚¹] â€”â€” [ä¸ºä»€ä¹ˆåŒæ„]\n\n"
    
    report += "**æˆ‘å­˜ç–‘çš„è§‚ç‚¹**:\n"
    report += "1. [è§‚ç‚¹] â€”â€” [ä¸ºä»€ä¹ˆå­˜ç–‘]\n"
    report += "2. [è§‚ç‚¹] â€”â€” [ä¸ºä»€ä¹ˆå­˜ç–‘]\n\n"
    
    report += "**æˆ‘ä¸åŒæ„çš„è§‚ç‚¹**:\n"
    report += "1. [è§‚ç‚¹] â€”â€” [ä¸ºä»€ä¹ˆä¸åŒæ„]\n\n"
    
    return report


def main():
    parser = argparse.ArgumentParser(description='æ·±åº¦æ€è€ƒç”Ÿæˆå™¨ v8.0')
    parser.add_argument('--input', required=True, help='è¾“å…¥è½¬å½•æ–‡æœ¬æ–‡ä»¶')
    parser.add_argument('--output', required=True, help='è¾“å‡ºæŠ¥å‘Šæ–‡ä»¶')
    
    args = parser.parse_args()
    
    # è¯»å–è¾“å…¥
    input_path = Path(args.input)
    if not input_path.exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨ï¼š{input_path}")
        return 1
    
    with open(input_path, 'r', encoding='utf-8') as f:
        text = f.read()
    
    print(f"ğŸ“– åŠ è½½ï¼š{input_path}")
    print(f"ğŸ“Š é•¿åº¦ï¼š{len(text):,} å­—")
    
    # ç”ŸæˆæŠ¥å‘Š
    print("\nâœï¸  ç”Ÿæˆæ·±åº¦æ€è€ƒæŠ¥å‘Š...")
    report = generate_deep_thinking(text)
    
    # ä¿å­˜
    output_path = Path(args.output)
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"\nâœ… å·²ä¿å­˜ï¼š{output_path}")
    print(f"ğŸ“„ å¤§å°ï¼š{output_path.stat().st_size:,} å­—èŠ‚")
    
    return 0


if __name__ == '__main__':
    exit(main())
